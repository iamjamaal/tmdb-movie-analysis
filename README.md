# ğŸ¬ TMDB Movie Data Analysis Pipeline

A production-grade, scalable data engineering pipeline for analyzing movie data from The Movie Database (TMDB) API using Apache Spark, Airflow, and modern data engineering practices.

## ğŸ“Š Project Overview

This project transforms raw movie data from TMDB API into actionable insights through:
- **Distributed Data Processing** with Apache Spark
- **Workflow Orchestration** with Apache Airflow
- **Intelligent Caching** with Redis
- **Data Quality Validation** with custom validators
- **Advanced Analytics** with comprehensive KPIs
- **Interactive Visualizations** with Matplotlib/Seaborn

## Key Features

### Data Engineering
 **Scalable Architecture**: Spark cluster for distributed processing  
 **Automated Workflows**: Airflow DAGs for orchestration  
 **Smart Caching**: Redis-based caching to minimize API calls  
 **Rate Limiting**: Token bucket algorithm for API protection  
 **Error Handling**: Comprehensive retry logic and fallback mechanisms  

### Data Quality
 **Schema Validation**: Automated schema checking  
 **Business Rule Validation**: Custom validation rules  
 **Data Completeness Checks**: Missing value detection  
 **Outlier Detection**: Statistical anomaly identification  
 **Quality Scoring**: Overall data health metrics  

### Analytics & KPIs
 **Financial Metrics**: Revenue, profit, ROI calculations  
 **Performance Rankings**: Top/bottom movies by various metrics  
 **Temporal Analysis**: Yearly trends and patterns  
 **Genre Analysis**: Genre-specific performance metrics  
 **Franchise Comparison**: Franchise vs standalone analysis  
 **Director Analytics**: Director performance metrics  

### Visualization
 **Interactive Dashboards**: Web-based reporting    
 **Correlation Plots**: Multi-dimensional analysis  
 **Distribution Charts**: Statistical distributions  

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              User Interface Layer               â”‚
â”‚   JupyterLab â”‚ Airflow UI â”‚ Grafana â”‚ Reports  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Orchestration Layer                   â”‚
â”‚           Apache Airflow                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Processing Layer                      â”‚
â”‚   Spark Master â†â†’ Worker-1 â†â†’ Worker-2         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Data Layer                         â”‚
â”‚   PostgreSQL â”‚ Redis Cache â”‚ File Storage      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

##  Project Structure

```
tmdb-movie-analysis/
â”œâ”€â”€ docker/                      # Docker configurations
â”‚   â”œâ”€â”€ docker-compose.yml      # Multi-service orchestration
â”‚   â”œâ”€â”€ Dockerfile.spark        # Spark image
â”‚   â”œâ”€â”€ Dockerfile.airflow      # Airflow image
â”‚   â””â”€â”€ Dockerfile.jupyter      # Jupyter image
â”‚
â”œâ”€â”€ airflow/                     # Airflow components
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ tmdb_pipeline_dag.py
â”‚   â”œâ”€â”€ plugins/
â”‚   â””â”€â”€ config/
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.yaml         # Central configuration
â”‚   â”‚   â””â”€â”€ logging_config.py   # Logging setup
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/              # Data fetching
â”‚   â”‚   â”œâ”€â”€ api_client.py       # TMDB API client
â”‚   â”‚   â””â”€â”€ data_fetcher.py     # Data fetching logic
â”‚   â”‚
â”‚   â”œâ”€â”€ processing/             # Data processing
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py     # Data cleaning
â”‚   â”‚   â”œâ”€â”€ data_transformer.py # Feature engineering
â”‚   â”‚   â””â”€â”€ data_validator.py   # Quality validation
â”‚   â”‚
â”‚   â”œâ”€â”€ analytics/              # Analytics & KPIs
â”‚   â”‚   â”œâ”€â”€ kpi_calculator.py   # KPI calculations
â”‚   â”‚   â”œâ”€â”€ advanced_queries.py # Complex queries
â”‚   â”‚   â””â”€â”€ metrics_aggregator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/          # Visualizations
â”‚   â”‚   â””â”€â”€ dashboard_generator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                  # Utilities
â”‚   â”‚   â”œâ”€â”€ spark_session.py    # Spark management
â”‚   â”‚   â””â”€â”€ helpers.py          # Helper functions
â”‚   â”‚
â”‚   â””â”€â”€ main.py                 # Main pipeline
â”‚
â”œâ”€â”€ tests/                       # Test suite
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ conftest.py
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks
â”‚   â””â”€â”€ exploratory_analysis.ipynb
â”‚
â”œâ”€â”€ data/                        # Data directories
â”‚   â”œâ”€â”€ raw/                    # Raw API data
â”‚   â”œâ”€â”€ processed/              # Cleaned data
â”‚   â””â”€â”€ output/                 # Results & reports
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ architecture.md
â”‚   â””â”€â”€ api_documentation.md
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ Makefile                    # Automation commands
â””â”€â”€ README.md                   # This file
```

4. **Access the applications**
- **Airflow**: http://localhost:8081 (admin/admin)
- **Spark Master UI**: http://localhost:8080
- **JupyterLab**: http://localhost:8888
- **Grafana**: http://localhost:3000 (admin/admin)

5. **Run the pipeline**
```bash
# Via Airflow UI (recommended)
# Navigate to http://localhost:8081 and trigger the DAG

# Or via command line
make run-pipeline
```


##  Pipeline Stages

### 1. Data Ingestion
- Fetches movie data from TMDB API
- Implements rate limiting and caching
- Handles API failures with retry logic

### 2. Data Cleaning
- Removes irrelevant columns
- Handles missing values
- Fixes data type issues
- Removes duplicates
- Standardizes formats

### 3. Data Transformation
- Feature engineering
- Calculated fields (profit, ROI)
- Date parsing and extraction
- Multi-value field processing

### 4. Data Validation
- Schema validation
- Business rule checks
- Data quality scoring
- Outlier detection

### 5. Analytics & KPIs
- Financial metrics (revenue, profit, ROI)
- Performance rankings
- Genre analysis
- Director/franchise analytics
- Temporal trends

### 6. Visualization
- Revenue vs budget plots
- Genre distributions
- Yearly trends
- ROI distributions
- Rating correlations
- Franchise comparisons

##  Sample KPIs

### Financial Metrics
- **Highest Revenue Movies**
- **Highest Profit Movies**
- **Best ROI (Budget â‰¥ $10M)**
- **Worst ROI**

### Quality Metrics
- **Highest Rated Movies** (min 10 votes)
- **Most Popular Movies**
- **Most Voted Movies**

### Analysis Queries
- Franchise vs Standalone comparison
- Genre-specific performance
- Director performance metrics
- Yearly box office trends



### Dashboards
- **Grafana**: Real-time metrics (http://localhost:3000)
- **Spark UI**: Job execution details (http://localhost:8080)
- **Airflow UI**: Workflow status (http://localhost:8081)


